Introduction:
An American computer scientist named John McCarthy first used the term ‘Artificial Intelligence’ in 1956.He was one of the founders of the discipline of Artificial Intelligence.
Artificial Intelligence is where the machine is capable of mimicking the problem-solving techniques as that of a human. Before getting in-depth about the topic knowing the very basics are essential and so here they are. There are three levels of Artificial Intelligence namely Artificial Narrow Intelligence or also known as the weak Artificial Intelligence is where the machine focuses on only one task, Artificial General Intelligence is where the machine is capable of imitating the intellectual tasks as that of a human and last and final level is Artificial Strong Intelligence is where the machine is much smarter than a human in many ways. AI simulates human perception and decision-making processes using deep learning models to control actions in driver control systems, such as steering and brakes. And even with the creation of self-driving cars, we are still in the first level of Artificial Intelligence. Deep Learning has seized the majority of the subfields of self-driving cars. Deep learning is a subset of Artificial Intelligence and both AI and Deep learning are key technologies in piloted driving. 


There are different of automation that differentiate the model based on its activities. Level 1 is where the human is responsible for accelerating, steering, braking, monitoring, and the machine steers or accelerates but not both. Level 2 is where the human is responsible for monitoring and the machine does the steering and accelerating. The self-driving cars today like Tesla Autopilot, Cadillac Super Cruize, Nissan ProPilot Assist, and Volvo IntelliSafe are classified as level 2. Level 3 the machine monitors and applies brakes under conditions and the human intervenes if something goes wrong. In level 4 the machine can fully drive on its own but only when the machine predicts the traffic to be safe to drive. And the last and final level 5 is where the human’s intervention is not needed and the machine can fully function on its own. 


The first autonomous vehicle called ALVINN (Artificial Land Vehicle In a Neural Network) was created in 1989. It used neural networks to detect lanes, ground, and drive.this vehicle used an end-to-end approach, The image was fed to the neural network which stimulated a steering angle. As mentioned before deep learning has taken over the majority of the subfields in autonomous vehicles and a  few of them are listed below. 


To make it safe deep learning is applied in various parts of the vehicle. The first and most important application is perception, which is to detect the objects in the vehicle’s way and the lanes in which it can move. This is done by using 3 main sensors namely, the Camera, The Light Detection Ranging (LiDAR), and Radio Detection Ranging(RADAR).


Localization is about determining the position of the vehicle and drawing a bounding box around it. And to do this the first thing that comes to mind is GPS but sometimes they can be inaccurate and not show the route perfectly every time like when the weather is cloudy. However, GPS is accurate only 1 to 2 cm, while we need 1 to 3 cm. This is, on the whole, creating a field called Localization. Depending on the choice of algorithm, we have many ways to do localization namely knowing the map and initial position, knowing the map but not the initial position, and knowing neither the map nor the initial position. 


Control is about following the trajectory by generating a steering angle and an acceleration value. For example, when driving on hill stations where the roads are just too curvy the angle the car has to turn and the acceleration speed required to make the turn safe is the job of control. Deep Reinforcement Learning models are being used in Control. Algorithms used in Control are Proportional Integral Derivatives (PID), Model Predictive Control (MPC).


Planning is the major component of autonomous driving. There are different types of planning. High-level planning is more like Google Maps where the program finds a route from the source to destination. And for that algorithms like A*, Depth First Search (DFS), Breadth-First Search (BFS).  Behavioral planning is predicting how the object moves and where it will be soon. This also includes Decision making where we either give manual inputs and generate a Finite State Machine or use Reinforcement learning techniques. The next type is Path planning. High-level planning tells us where to go but what if cars are blocking you? or if the traffic light is red? or children cross all of a sudden in the middle of the road? That’s where Path planning comes in and we have to modify the generated trajectory. For this algorithms such as Rapidly-exploring Random Trees (RRT), RRT*, Probabilistic Roadmaps (PRM), PRM* are used.


When it comes to Decision making, the car detects an object, identifies it, Interprets the object, and then makes a decision using object detection and object classification algorithms such as SIFT Scale Invariant Feature Transform is an algorithm used for object detection and object, AdaBoost for data classification, where this algorithm collects the data and classifies it which boosts the process and the performance of the vehicle. TextonBoost algorithm is also used for object detection but it reads the data in the form of shapes. HOG (Histogram of Oriented Gradient)  algorithm is used to analyze an object’s location. YOLO ( You Only Look Once) algorithm is used to identify and group the objects (Eg: Humans and Cars). 


The most common open-source Datasets used in autonomation driving are :
Astyx Data set HiRes (2019) is a radar dataset used for detecting 3D objects. This data set provides high-resolution radar data to apply to algorithms that use radar sensor data. This data set is about 350MB and it has 546 frames. Oxford Radar RobotCar dataset consists of 100 routes through Oxford and the UK. This dataset was made by capturing the routes for over a year. The dataset has combinations of data such as Traffic, weather, pedestrians, and also construction and road works. Pandaset dataset is a popular large-scale dataset used on autonomous vehicles projects. This dataset has 20k Lidar, 60K camera, 28 annotation classes, and 37 segmentation labels, and many more features.